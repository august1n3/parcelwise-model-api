{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30929495",
   "metadata": {
    "papermill": {
     "duration": 0.00332,
     "end_time": "2025-09-01T22:12:30.519954",
     "exception": false,
     "start_time": "2025-09-01T22:12:30.516634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing important python Libraries**\n",
    "* pandas\n",
    "* numpy\n",
    "* sklearn(GradientBoostingRegressor, train_test_split, LabelEncoder)\n",
    "* network\n",
    "* heapq\n",
    "* math(radians, sin, cos, sqrt, atan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fcb992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:12:30.526513Z",
     "iopub.status.busy": "2025-09-01T22:12:30.526252Z",
     "iopub.status.idle": "2025-09-01T22:12:34.181168Z",
     "shell.execute_reply": "2025-09-01T22:12:34.180354Z"
    },
    "papermill": {
     "duration": 3.659942,
     "end_time": "2025-09-01T22:12:34.182588",
     "exception": false,
     "start_time": "2025-09-01T22:12:30.522646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "from math import radians, sin, cos, sqrt, atan2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819e0d9",
   "metadata": {
    "papermill": {
     "duration": 0.002591,
     "end_time": "2025-09-01T22:12:34.188380",
     "exception": false,
     "start_time": "2025-09-01T22:12:34.185789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Loading dataset (delivery_five_cities_tanzania.csv)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629012a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:12:34.194493Z",
     "iopub.status.busy": "2025-09-01T22:12:34.194115Z",
     "iopub.status.idle": "2025-09-01T22:12:37.900270Z",
     "shell.execute_reply": "2025-09-01T22:12:37.899726Z"
    },
    "papermill": {
     "duration": 3.710817,
     "end_time": "2025-09-01T22:12:37.901697",
     "exception": false,
     "start_time": "2025-09-01T22:12:34.190880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "#load your data from a file (e.g., CSV).\n",
    "file_path = './delivery_five_cities_tanzania.csv'\n",
    "\n",
    "print(\"Step 1: Loading dataset...\")\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b98e78",
   "metadata": {
    "papermill": {
     "duration": 0.002382,
     "end_time": "2025-09-01T22:12:37.907004",
     "exception": false,
     "start_time": "2025-09-01T22:12:37.904622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Processing and Feature Enginering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "654ca323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:12:37.912741Z",
     "iopub.status.busy": "2025-09-01T22:12:37.912506Z",
     "iopub.status.idle": "2025-09-01T22:12:45.731784Z",
     "shell.execute_reply": "2025-09-01T22:12:45.731182Z"
    },
    "papermill": {
     "duration": 7.823701,
     "end_time": "2025-09-01T22:12:45.733115",
     "exception": false,
     "start_time": "2025-09-01T22:12:37.909414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Preprocessing and Feature Engineering...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Step 2: Preprocessing and Feature Engineering...\")\n",
    "\n",
    "# Convert the string dates to a datetime objects\n",
    "df['sign_time'] = pd.to_datetime(df['sign_time'], format='%m-%d %H:%M:%S')\n",
    "df['receipt_time'] = pd.to_datetime(df['receipt_time'], format='%m-%d %H:%M:%S')\n",
    "\n",
    "# Calculate the target variable: travel time in minutes\n",
    "df['travel_time_minutes'] = (df['sign_time'] - df['receipt_time']).dt.total_seconds() / 60\n",
    "\n",
    "# Extract temporal features\n",
    "df['hour'] = df['receipt_time'].dt.hour\n",
    "df['day_of_week'] = df['receipt_time'].dt.dayofweek\n",
    "\n",
    "# Haversine distance function to calculate straight-line distance (in km)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "# Calculate straight-line distance using the haversine() function\n",
    "df['distance_km'] = df.apply(\n",
    "    lambda row: haversine(row['receipt_lat'], row['receipt_lng'], row['sign_lat'], row['sign_lng']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Encode categorical features\n",
    "le = LabelEncoder()\n",
    "df['city_encoded'] = le.fit_transform(df['from_city_name'])\n",
    "df['typecode_encoded'] = le.fit_transform(df['typecode'])\n",
    "\n",
    "# Define features and target\n",
    "features = ['receipt_lng', 'receipt_lat', 'sign_lng', 'sign_lat', 'hour', 'day_of_week', 'distance_km', 'city_encoded', 'typecode_encoded']\n",
    "target = 'travel_time_minutes'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1399279",
   "metadata": {
    "papermill": {
     "duration": 0.002495,
     "end_time": "2025-09-01T22:12:45.738565",
     "exception": false,
     "start_time": "2025-09-01T22:12:45.736070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Selection and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f6104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:12:45.744370Z",
     "iopub.status.busy": "2025-09-01T22:12:45.744159Z",
     "iopub.status.idle": "2025-09-01T22:14:14.811749Z",
     "shell.execute_reply": "2025-09-01T22:14:14.810926Z"
    },
    "papermill": {
     "duration": 89.074458,
     "end_time": "2025-09-01T22:14:14.815550",
     "exception": false,
     "start_time": "2025-09-01T22:12:45.741092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Step 3: Training the Gradient Boosting Regressor model...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(model, 'parcel_wise_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef55c4",
   "metadata": {
    "papermill": {
     "duration": 0.003518,
     "end_time": "2025-09-01T22:14:14.821944",
     "exception": false,
     "start_time": "2025-09-01T22:14:14.818426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Building the Hybrid System with a Graph Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a984fb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:14:14.828491Z",
     "iopub.status.busy": "2025-09-01T22:14:14.828051Z",
     "iopub.status.idle": "2025-09-01T22:15:02.198999Z",
     "shell.execute_reply": "2025-09-01T22:15:02.198379Z"
    },
    "papermill": {
     "duration": 47.375914,
     "end_time": "2025-09-01T22:15:02.200535",
     "exception": false,
     "start_time": "2025-09-01T22:14:14.824621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Building the hybrid model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 4: Building the hybrid model...\")\n",
    "\n",
    "# Create a graph from your data\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes (locations) to the graph. We use a tuple of (lng, lat) as a unique node ID.\n",
    "for index, row in df.iterrows():\n",
    "    start_node = (row['receipt_lng'], row['receipt_lat'])\n",
    "    end_node = (row['sign_lng'], row['sign_lat'])\n",
    "    G.add_node(start_node)\n",
    "    G.add_node(end_node)\n",
    "    \n",
    "# Add edges with weights (actual travel time for demonstration)\n",
    "for index, row in df.iterrows():\n",
    "    start_node = (row['receipt_lng'], row['receipt_lat'])\n",
    "    end_node = (row['sign_lng'], row['sign_lat'])\n",
    "    G.add_edge(start_node, end_node, weight=row['travel_time_minutes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5635dd0",
   "metadata": {
    "papermill": {
     "duration": 0.002686,
     "end_time": "2025-09-01T22:15:02.206696",
     "exception": false,
     "start_time": "2025-09-01T22:15:02.204010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Visualizing the graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f92b5c2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:15:02.213191Z",
     "iopub.status.busy": "2025-09-01T22:15:02.212984Z",
     "iopub.status.idle": "2025-09-01T22:15:17.335084Z",
     "shell.execute_reply": "2025-09-01T22:15:17.334212Z"
    },
    "papermill": {
     "duration": 15.126916,
     "end_time": "2025-09-01T22:15:17.336381",
     "exception": false,
     "start_time": "2025-09-01T22:15:02.209465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Exporting the graph to a GEXF file...\n",
      "Graph successfully exported to 'sample_graph.gexf'\n",
      "You can now open this file in a tool like Gephi or Cytoscape.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def export_graph(graph, filename=\"exported_graph.gexf\"):\n",
    "    \"\"\"\n",
    "    Exports the graph to a GEXF file for visualization in other tools.\n",
    "    \n",
    "    Args:\n",
    "        graph (networkx.DiGraph): The graph to export.\n",
    "        filename (str): The name of the output file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nx.write_gexf(graph, filename)\n",
    "        print(f\"Graph successfully exported to '{filename}'\")\n",
    "        print(\"You can now open this file in a tool like Gephi or Cytoscape.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting graph: {e}\")\n",
    "\n",
    "print(\"Step 5: Exporting the graph to a GEXF file...\")\n",
    "# We will export the small sample graph for demonstration purposes.\n",
    "# For your full graph, you would call `export_graph(G)` after building it.\n",
    "export_graph(G, \"sample_graph.gexf\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9f2e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:15:17.343616Z",
     "iopub.status.busy": "2025-09-01T22:15:17.343388Z",
     "iopub.status.idle": "2025-09-01T22:15:17.350008Z",
     "shell.execute_reply": "2025-09-01T22:15:17.349327Z"
    },
    "papermill": {
     "duration": 0.011384,
     "end_time": "2025-09-01T22:15:17.351033",
     "exception": false,
     "start_time": "2025-09-01T22:15:17.339649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prediction function to be used as a dynamic edge weight\n",
    "def predict_travel_time(start_loc, end_loc, timestamp, features_model):\n",
    "    \"\"\"\n",
    "    This function simulates using the trained ML model to predict travel time\n",
    "    for a new route segment.\n",
    "    \"\"\"\n",
    "    # Create a dummy DataFrame with the new features\n",
    "    new_data = pd.DataFrame([{\n",
    "        'receipt_lng': start_loc[0],\n",
    "        'receipt_lat': start_loc[1],\n",
    "        'sign_lng': end_loc[0],\n",
    "        'sign_lat': end_loc[1],\n",
    "        'hour': timestamp.hour,\n",
    "        'day_of_week': timestamp.dayofweek,\n",
    "        'distance_km': haversine(start_loc[1], start_loc[0], end_loc[1], end_loc[0]),\n",
    "        'city_encoded': 0, # Placeholder, as we don't know the city for a new route\n",
    "        'typecode_encoded': 0, # Placeholder\n",
    "    }])\n",
    "    \n",
    "    # Predict the travel time\n",
    "    predicted_time = features_model.predict(new_data[features])[0]\n",
    "    return max(0, predicted_time) # Ensure predicted time is not negative\n",
    "\n",
    "# Implement the A* search algorithm\n",
    "def a_star_search(graph, start_node, end_node, timestamp, model):\n",
    "    \"\"\"\n",
    "    A* search algorithm to find the shortest path based on predicted travel times.\n",
    "    \"\"\"\n",
    "    # Priority queue to store nodes to visit\n",
    "    queue = [(0, start_node, [start_node])]\n",
    "    # Set to keep track of visited nodes to avoid cycles\n",
    "    visited = {start_node: 0}\n",
    "    \n",
    "    while queue:\n",
    "        (cost, current_node, path) = heapq.heappop(queue)\n",
    "        \n",
    "        # Goal check\n",
    "        if current_node == end_node:\n",
    "            return path, cost\n",
    "        \n",
    "        # Explore neighbors\n",
    "        for neighbor in graph.neighbors(current_node):\n",
    "            \n",
    "            # Predict travel time for the edge using our ML model\n",
    "            edge_weight = predict_travel_time(current_node, neighbor, timestamp, model)\n",
    "            new_cost = cost + edge_weight\n",
    "            \n",
    "            if neighbor not in visited or new_cost < visited[neighbor]:\n",
    "                visited[neighbor] = new_cost\n",
    "                new_path = path + [neighbor]\n",
    "                # Heuristic: straight-line distance to the end node\n",
    "                heuristic_cost = haversine(neighbor[1], neighbor[0], end_node[1], end_node[0])\n",
    "                heapq.heappush(queue, (new_cost + heuristic_cost, neighbor, new_path))\n",
    "                \n",
    "    return None, float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78724b",
   "metadata": {
    "papermill": {
     "duration": 0.002703,
     "end_time": "2025-09-01T22:15:17.356544",
     "exception": false,
     "start_time": "2025-09-01T22:15:17.353841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Implement a function which takes consideration of new location before performing A star search algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86aac62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:15:17.363022Z",
     "iopub.status.busy": "2025-09-01T22:15:17.362814Z",
     "iopub.status.idle": "2025-09-01T22:15:17.368478Z",
     "shell.execute_reply": "2025-09-01T22:15:17.367832Z"
    },
    "papermill": {
     "duration": 0.010188,
     "end_time": "2025-09-01T22:15:17.369589",
     "exception": false,
     "start_time": "2025-09-01T22:15:17.359401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_optimal_path_for_new_delivery(graph, start_loc, end_loc, timestamp, model, num_neighbors=3):\n",
    "    \"\"\"\n",
    "    Finds the optimal path for a new delivery that may have locations not in the graph.\n",
    "    It does this by augmenting the graph with the new locations and connections\n",
    "    to the nearest known points in the network.\n",
    "    \"\"\"\n",
    "    # Create a temporary copy of the graph to avoid modifying the original\n",
    "    temp_graph = graph.copy()\n",
    "\n",
    "    # Add new start and end nodes if they don't already exist\n",
    "    if start_loc not in temp_graph:\n",
    "        temp_graph.add_node(start_loc)\n",
    "    if end_loc not in temp_graph:\n",
    "        temp_graph.add_node(end_loc)\n",
    "        \n",
    "    # Find the nearest neighbors to the new locations\n",
    "    existing_nodes = list(graph.nodes())\n",
    "    start_neighbors = sorted(existing_nodes, key=lambda loc: haversine(start_loc[1], start_loc[0], loc[1], loc[0]))[:num_neighbors]\n",
    "    end_neighbors = sorted(existing_nodes, key=lambda loc: haversine(end_loc[1], end_loc[0], loc[1], loc[0]))[:num_neighbors]\n",
    "    \n",
    "    # Add virtual edges from the new start node to its nearest neighbors\n",
    "    for neighbor in start_neighbors:\n",
    "        weight = predict_travel_time(start_loc, neighbor, timestamp, model)\n",
    "        temp_graph.add_edge(start_loc, neighbor, weight=weight)\n",
    "        \n",
    "    # Add virtual edges from the nearest neighbors to the new end node\n",
    "    for neighbor in end_neighbors:\n",
    "        weight = predict_travel_time(neighbor, end_loc, timestamp, model)\n",
    "        temp_graph.add_edge(neighbor, end_loc, weight=weight)\n",
    "        \n",
    "    # Run the A* search on the augmented graph\n",
    "    return a_star_search(temp_graph, start_loc, end_loc, timestamp, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c34c1c",
   "metadata": {
    "papermill": {
     "duration": 0.002642,
     "end_time": "2025-09-01T22:15:17.375123",
     "exception": false,
     "start_time": "2025-09-01T22:15:17.372481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Demonstrating the hybrid model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c39dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-01T22:15:17.381497Z",
     "iopub.status.busy": "2025-09-01T22:15:17.381299Z",
     "iopub.status.idle": "2025-09-01T22:15:33.793632Z",
     "shell.execute_reply": "2025-09-01T22:15:33.792779Z"
    },
    "papermill": {
     "duration": 16.416938,
     "end_time": "2025-09-01T22:15:33.794907",
     "exception": false,
     "start_time": "2025-09-01T22:15:17.377969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Demonstrating the hybrid model...\n",
      "Finding the optimal route for existing locations: (-8.923860028735865, 33.4214411329554) -> (-3.3714501814517206, 36.66093210406623)...\n",
      "\n",
      "Optimal Path (based on ML predictions):\n",
      "  1. (-8.923860028735865, 33.4214411329554)\n",
      "  2. (32.86782089052361, -2.466427364319329)\n",
      "  3. (-3.3714501814517206, 36.66093210406623)\n",
      "\n",
      "Total Predicted Travel Time: 6028.11 minutes\n",
      "\n",
      "==================================================\n",
      "\n",
      "Finding the optimal route for NEW locations: (12.98, 33.42) -> (12.96, 77.58)...\n",
      "\n",
      "Optimal Path for NEW Locations:\n",
      "  1. (12.98, 33.42)\n",
      "  2. (32.86786736066511, -2.466413007056262)\n",
      "  3. (12.96, 77.58)\n",
      "\n",
      "Total Predicted Travel Time: 9270.63 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 5: Demonstrating the hybrid model...\")\n",
    "\n",
    "#Locations are in the dataset but probably not in the training data\n",
    "start_location = (-8.923860028735865,33.4214411329554)\n",
    "end_location = (-3.3714501814517206,36.66093210406623)\n",
    "\n",
    "print(f\"Finding the optimal route for existing locations: {start_location} -> {end_location}...\")\n",
    "current_timestamp = pd.to_datetime('2025-09-01 14:00')\n",
    "optimal_path, total_time = find_optimal_path_for_new_delivery(G, start_location, end_location, current_timestamp, model)\n",
    "if optimal_path:\n",
    "    print(\"\\nOptimal Path (based on ML predictions):\")\n",
    "    for i, node in enumerate(optimal_path):\n",
    "        print(f\"  {i+1}. {node}\")\n",
    "    print(f\"\\nTotal Predicted Travel Time: {total_time:.2f} minutes\")\n",
    "else:\n",
    "    print(\"\\nNo path found between the specified locations.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example 2: New locations not in the dataset\n",
    "# These coordinates are intentionally new to the graph\n",
    "start_location_new = (12.9800, 33.420)\n",
    "end_location_new = (12.9600, 77.5800)\n",
    "\n",
    "print(f\"Finding the optimal route for NEW locations: {start_location_new} -> {end_location_new}...\")\n",
    "optimal_path_new, total_time_new = find_optimal_path_for_new_delivery(G, start_location_new, end_location_new, current_timestamp, model)\n",
    "\n",
    "if optimal_path_new:\n",
    "    print(\"\\nOptimal Path for NEW Locations:\")\n",
    "    for i, node in enumerate(optimal_path_new):\n",
    "        print(f\"  {i+1}. {node}\")\n",
    "    print(f\"\\nTotal Predicted Travel Time: {total_time_new:.2f} minutes\")\n",
    "else:\n",
    "    print(\"\\nNo path found between the specified new locations.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 440120,
     "modelInstanceId": 422554,
     "sourceId": 554833,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 190.350438,
   "end_time": "2025-09-01T22:15:36.724576",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-01T22:12:26.374138",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
